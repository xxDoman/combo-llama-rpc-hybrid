# ğŸš€ Combo-Llama: Hybrid NVIDIA + AMD (MI50) VRAM Cluster
### Performance-Optimized Distributed Inference (RTX 40-Series & GFX906)

**Combo-Llama** to profesjonalny klaster LLM, ktÃ³ry agreguje **44GB VRAM** z kart **NVIDIA RTX 4070 (12GB)** oraz **AMD Instinct MI50 (32GB)**.

## ğŸ“Š DowÃ³d WydajnoÅ›ci (55.83 tokens/s)
![Cluster Performance Dashboard](dashboard.png)
*PowyÅ¼szy zrzut ekranu przedstawia system podczas generowania 2048 tokenÃ³w.*

### ğŸ“ˆ Analiza ObciÄ…Å¼enia (Snapshot z testu):
| PodzespÃ³Å‚ | Wykorzystanie GPU | VRAM | Rola w systemie |
| :--- | :--- | :--- | :--- |
| **AMD MI50** | **89%** | **~18 GB** | GÅ‚Ã³wna moc obliczeniowa (Compute) |
| **NVIDIA 4070** | **12%** | **~6.7 GB** | Master Node / KV Cache / API |

> **Werdykt Techniczny:** Niskie obciÄ…Å¼enie karty NVIDIA (12%) przy jednoczesnym wysokim obciÄ…Å¼eniu AMD (89%) ostatecznie potwierdza **bottleneck na szynie PCIe Gen 4 x4**. System generuje tokeny tak szybko, jak pozwala na to interfejs komunikacyjny, a nie same rdzenie GPU.

## ğŸ§  Optymalizacja VRAM i Kontekstu
DziÄ™ki flagom `--parallel 1` oraz `--ctx-size 32768`, klaster oszczÄ™dza **15GB VRAM**, pozwalajÄ…c na pracÄ™ z modelami **30B (Q5)** przy zachowaniu "pamiÄ™ci" o dÅ‚ugoÅ›ci ok. 60 stron tekstu.

## ğŸ› ï¸ Hardware & Cooling
- **RTX 4070:** Pracuje w trybie niskiego poboru mocy (~50W).
- **MI50:** DziÄ™ki autorskiemu chÅ‚odzeniu aktywnemu, karta utrzymuje **~51Â°C** przy peÅ‚nym obciÄ…Å¼eniu (1725MHz SCLK). [Wiki ChÅ‚odzenia](https://github.com/xxDoman/ollama-amd-rocm71-vl/wiki).

## ğŸš€ Szybki Start
1. WrzuÄ‡ model do `./guff/`.
2. Uruchom: `docker compose up -d`.
3. Testuj: `./bench_long.sh`.

---
Developed by **xxdoman** | AI Master of Disaster | 2026-01-15
